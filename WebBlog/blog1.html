<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Usable Security Blog</title>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" type="text/css" href="home.css">
    </head>

    <div class="header">
        <h2>CSCI 497S</h2>
        <h1>Usable Security Blog</h1>
        <h6>By Joshua Knight</h6>
    </div>

    <div class="row">
        <div class="leftcol">
            <div class="card">
                <h2>Introduction to Usable Security</h2>
                <h5>Week One, April 10, 2020</h5>
                <div class="image" style="height:200px;">
                    <img src="two-gifs-meme.jpg" alt="What Would You Do?">
                </div>
                <br><br>
                <br><br>
                <br>
                <br>
                <p> 
                    Now in my senior year of courses in the Western Washington University cyber security program, most of our focus has been about how technology based cyber security should be implemented into various different environments. This has largely centered around how the technical elements of cyber security should be applied to resolving human problems, ascertaining and meeting the risk appetite of a company, or secure coding and software design habits. This curriculum has not gone into great depth at looking at how humans tend to intact with technology itself. Sure, we have talked about the problem’s humans have with picking or reusing passwords or the dangers of BYOD (bringing your own device) in the work place. But next to nothing about how an average user normally interact with the various systems that they are assigned to use. So far very early in this course (CSCI 497S – Usable Security) the dialogue is very alien to that norm. Rather than what technology decisions must be made to effectively apply security within an entity, the field on usable security looks to ingrain human elements into the technical problems of designing and implementing security. That is to suggest that the rigidity of technical solutions when removed from the particulars of human users might exist at the core of many problems within cyber security in an organization.<br>
                </p>
                <p>We have all heard it, or perhaps even are guilty of grumbled it under our breath to ourselves, that timeless adage, P.E.B.K.A.C. (problem exists between keyboard and chair). After all technical software solutions do what they are designed to do, right? Thus, it is the user who must be at fault for most if not all the problems that occur when utilizing sociotechnical systems. But if we pause that line of thinking momentarily; that is after all what humans do, we break things, or rather take things that do not work for us and make them to do so, even if circumvents the original designers intended usage. That is our brilliance and perhaps at times also our folly, but it remains a universal truth that should be accounted for during throughout the lifetime of any sociotechnical solution. During design the question should be regularly asked of a solution “this is how we intend for this to be utilized, but how else might it be used?” During implementation, and testing of a product there should be a constant feedback of information that says to a designer “this is how this is being used, is our design still adequate?” In the absence of these lines of thinking, the issues can not longer be viewed as user issues, they must be viewed as design issues. After all, if sociotechnical systems do what they are designed to do but they do not present obvious solutions to users, humans will do what they are designed to do also, adapt a solution to fit their intricate and unique needs. </p><br>
                <p>This certainly adds a challenging set of issues for a system designer to face; how can you possibly anticipate all the different ways a technical solution can be (mis)used? The answer is you can not fully actualize that, but by categorizing the varies different ways design can come into conflict with human behavior researchers have paved a way at attempting to simplify that process and better address the needs of users that would not otherwise be met.</p>
                <br>
                <h6>APA Citations</h6>
                <p>Norman, D. A., & Stappers, P. J. (2015). DesignX: Complex SociotechnicalSystems. She Ji, 83–107. Retrieved from http://www.journals.elsevier.com/she-ji-the-journal-of-design-economics-and-innovation</p>
                <p>On actor-network theory. A few clarifications plus more than a few complications. (1990). Finn Olsen, 25(3), 47–64.</p>
                <p>Payne , B. D., & Edwards, W. K. (2008). A Brief Introduction to Usable Security. Useful Computer Security, 13–21. doi: 4/10/2020</p>
            
            </div>
        </div>
        <div class="rightcol">
            <div class="card">
                <h3>About Me</h3>
                <div class="image" style="height:100px;">Image</div>
                <p>Some Text About Me</p>
            </div>
            <div class="card">
                <h3>Recent Posts</h3>
                <div class="image">Image</div><br>
                <div class="image">Image</div><br>
                <div class="image">Image</div><br>
            </div>
        </div>
    </div>

    <div class="footer">
        <h3>Footer</h3>
    </div>

</html>